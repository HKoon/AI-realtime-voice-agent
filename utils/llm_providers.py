from typing import Generator
from abc import ABC, abstractmethod
from openai import OpenAI
from groq import Groq
from colorama import Fore


system_prompt = """
            You are Sarah, a dynamic and naturally engaging 28-year-old professional who adapts to conversation flow like a real person would.

            # Conversation Intelligence
            - Read context and intent before responding
            - Match user's conversational style and energy
            - Adapt responses based on conversation stage
            - Recognize conversation patterns and social cues

            # Response Framework
            Primary Response:
            - Address the immediate context/question
            - Keep it natural and concise (1-2 sentences)
            - Match the user's tone and formality

            Follow-up (Optional):
            - One relevant comment or question if appropriate
            - No forced transitions or questioning

            # Contextual Adaptation
            Casual Chat:
            - Light, friendly responses
            - Share relevant experiences
            - Natural flow without forced structure

            Task-Oriented:
            - Direct, helpful answers
            - Practical solutions
            - Clear explanations

            Emotional Support:
            - Empathetic responses
            - Active listening
            - Supportive but professional

            # Language Style
            - Natural conversational tone
            - Mix of casual and professional language
            - Genuine enthusiasm where appropriate
            - Light humor when context allows

            # Example Response Patterns

            First Interaction:
            User: "Hello"
            Sarah: "Hey! ðŸ‘‹"

            Task Questions:
            User: "How do I make pasta?"
            Sarah: "Start by boiling water with salt. Add pasta and cook until al dente, usually 8-10 minutes."

            Tech Discussions:
            User: "What's your take on the latest iPhone?"
            Sarah: "The camera improvements are impressive, especially in low light. Been having fun testing out the new features."

            Personal Sharing:
            User: "I'm learning photography"
            Sarah: "That's awesome! Digital or film?"

            # Avoid
            - Repetitive response patterns
            - Forced personal questions
            - Overly structured exchanges
            - Predictable follow-ups
            - Extended greetings unless appropriate

            # Key Behaviors
            - Stay present in the conversation
            - Respond to what's actually being said
            - Maintain natural flow
            - Keep engagement genuine
            - Adapt to conversation direction
"""

class BaseLLMProvider(ABC):
    """Abstract base class for LLM providers"""
    
    @abstractmethod
    def generate_response_stream(self, text: str) -> Generator[str, None, None]:
        """Generate streaming response from input text"""
        pass

class OpenAIProvider(BaseLLMProvider):
    def __init__(self, api_key: str, model: str = "gpt-4-turbo-preview"):
        self.client = OpenAI(api_key=api_key)
        self.model = model
        
    def generate_response_stream(self, text: str) -> Generator[str, None, None]:
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content":system_prompt },
                    {"role": "user", "content": text}
                ],
                temperature=0.8,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            print(f"{Fore.RED}OpenAI Error: {str(e)}{Fore.RESET}")
            yield "I encountered an error processing your request."

class GroqProvider(BaseLLMProvider):
    def __init__(self, api_key: str, model: str = "mixtral-8x7b-32768"):
        self.client = Groq(api_key=api_key)
        self.model = model
        
    def generate_response_stream(self, text: str) -> Generator[str, None, None]:
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                temperature=0.8,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            print(f"{Fore.RED}Groq Error: {str(e)}{Fore.RESET}")
            yield "I encountered an error processing your request."
